# SQL 语言

熟悉 SQL 语法，能够编写 SQL 进行增删查改，解决实际的业务问题，熟悉各种 DML、DDL、DCL

# 顺序 IO 和随机 IO

数据是存在磁盘里面的，我们做的很多努力都是为了实现顺序 IO 来提高性能，尽量避免随机 IO

# 数据按照分页存储方式

一张表是怎么在磁盘表示的？所谓的页就是一块块独立的磁盘空间，例如一张表分成了很多个页存储在磁盘中，数据库系统与磁盘进行交互的最小单位就是页

# 数据按照日志存储方式

除了用页表示表数据，还可以用日志的方式，例如 INSERT xxx WHERE id = 1; UPDATE xxx WHERE id = 1; 将这两条日志按照顺序执行就能表示实际数据

# 系统目录（system catalogs）

库、表等信息会被维护起来，供我们直接查询，例如一个库下面有哪些表，一个表有哪些字段、索引等，一张表里面有多少行，都可以直接查出来，查询优化器在做一些优化预估的时候，会使用到这里面的数据

# OLTP（On-line Transaction Processing）

在线事务处理，代表一些简单、快速的增删查改，能够在高并发环境下执行的 SQL 语句

# OLAP（On-line Analtical Processing）

在线分析处理，代表一些复杂、执行缓慢的增删查改，不能够在高并发环境下执行的 SQL 语句，通常是把原来的数据复制出来，然后离线执行；大数据量处理（Data Lakes）

# 缓冲池（Buffer Pool）

增删查改的时候，并不是直接操作磁盘数据，而是将磁盘数据读到内存中，统一在内存进行增删查改，然后等待一定的时机再把这些“脏数据”刷新到磁盘里面。因此缓冲池的大小、刷盘频率都会对数据库性能产生影响。此外还有各种缓冲池优化技术，例如提前将数据缓存起来、设置多个缓冲池提高并发等，缓冲池也有很多类型分别存储不同类型的数据

# 内存淘汰策略

缓冲池满的时候，需要释放相应的内存，具体有 LRU 、LFU 算法

# 锁（Lock）

锁的目的是为了解决并发读写的问题，具体有：表锁、行锁、间隙锁、意向锁、两阶段锁、读锁、写锁、锁升级机制、死锁检测算法、死锁预防算法

# 哈希索引

使用哈希表作为索引，一般使用在数据量比较少的场景

# B+ 树索引

大部分磁盘数据库采用该数据结构实现索引，如 MySQL 的 InnoDB 存储引擎，主要特点是多路平衡树，数据都在叶子节点

# 连接管理模块

对外暴露客户端接口，负责客户端连接管理、权限验证等

# 语法分析模块

SQL 词法分析、语法分析

# 优化器模块

选择最优执行计划生成（Query Cost Models/Cost-based Optimization）、基于规则的语句优化与重写

# 执行器模块

负责与存储引擎进行对接、数据交互

# 存储引擎模块

负责与磁盘 IO，对外提供接口进行读写操作

# 文件排序算法

因为磁盘的容量远大于内存容量，我们需要文件排序来实现 ORDER BY 等的功能，例如 Top-N Heap Sort 和 External Merge Sort 等算法

# 文件分片聚合算法（Aggregation）

因为磁盘的容量远大于内存容量，当我们需要实现在 100 亿个 URL 中找到重复的 URL 这样的功能时，需要利用哈希函数将这些 URL 分配到不同的小文件上面，然后在每一个小文件里面统计重复 URL，由于哈希函数的性质，重复 URL 一定会分配到同一个文件里面的

# 回表

当存在二级索引的时候，二级索引查到的仅仅只是主键 id，需要拿着主键 id 去聚簇索引拿到完整的数据，这个过程是随机 IO，应该尽量避免大量的回表操作

# 连接算法

JOIN 语句的底层实现，主要分为三种：

第一种是：嵌套循环连接（Nested Loop Join），循环遍历 A 表的每一行的 join key 与 B 表的每一行的 join key 进行对比判断是否命中。业界经常做的性能优化“小表驱动大表”，本质上是将小表放在外循环，将大表放在内循环，并且内循环采用索引扫描的方式

第二种是：哈希连接（Hash Join），先循环遍历 A 表所有的 join key 保存在哈希表中，再循环遍历 B 表所有的 join key 若发现存在哈希表中，则命中

第三种是：归并连接（Sort-Merge Join），先对 A 表和 B 表分别进行排序，然后采用双指针分别指向 A 表和 B 表的 join key，分别移动指针进行两者对比判断是否命中

# 索引合并（Index Merge）

将多个二级索引的结果进行聚合然后再回表

# 联合索引

多个列组成同一个索引

# 聚簇索引（Cluster Index）

完整的行数据放在聚簇索引的叶子节点里面

# 二级索引

也称为非聚簇索引，不存储完整的行数据，只存储主键，在二级索引只能查到主键，如果需要完整数据，还需要拿着主键去回表

# 覆盖索引（Cover Index）

需要查询的数据只存在于二级索引中，不需要回表

# 索引下推（Index Condition Pushdown）

判断 WHERE 条件能用索引中的列来做检查，条件不满足，则处理下一行索引记录，不需要回表

# MVCC（多版本并发控制 Muti-Version Concurrency Control）

两个事务读、写可以并发执行而不会相互锁住对方的一种技术，也成为快照读，MySQL 使用了 undo log 做版本链

# 事务 ACID

原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）、持久性（Durability）

# 事务隔离级别（Isolation Level）

读未提交（脏读、可重复读、幻读）、读提交（可重复读、幻读）、可重复读（幻读）、串行化。值得一提的是，MySQL 在可重复读的隔离级别中没有幻读问题，由此可知不同的数据库会有不同的实现

# 故障恢复机制

事务执行到一半的时候机器宕机，在机器重启的时候要做相应的处理保证事务 ACID 的性质。MySQL 使用了 redo log 和 undo log 等来实现故障恢复

# 主从复制机制

以 MySQL 为例子，使用了 binlog 将主节点的数据同步给备节点，binlog 和 redo log 两者需要保证一致性使用了两阶段提交的机制

# 分布式数据库（Distributed DBMSs）

数据库集群高可用高性能（读写分离）、分布式共识算法、数据分片机制（水平分片、垂直分片）、分库分表（逻辑分片）、一致性哈希算法、CAP理论、BASE理论

# 分布式事务

# 日志

先写日志而不是直接更新真实数据（Write-Ahead Log）、定时将日志信息更新到真实数据需要记录检查点，每次从检查点开始扫描日志信息（LSN、Checkpoints）

