本文学习 Redis 架构演化之路，能够从 0 到 1 独自搭建一个 Redis 集群。

# 1 单机版 Redis

当业务体量小，性能要求不高时，可以部署一个单机版的 Redis：

业务应用可以把 Redis 当缓存使用，从数据库中查询数据，然后写入到 Redis 中，业务应用再从 Redis 中读取数据，由于 Redis 的数据都存储在内存中，所以速度很快。

随着业务体量增大，对 Redis 依赖也加重，假设 Redis 宕机，重启可以恢复服务，但是会丢失数据，这时就需要引入数据持久化的做法。


# 2 Redis 数据持久化

当 Redis 重启时，我们把磁盘中的数据快速恢复到内存中，这样它就可以继续正常提供服务


最容易想到的一个方案：Redis 每一次执行写操作，除了写内存外，同时也写一份到磁盘上，就像这样：

但是问题来了：客户端的每次写操作，既需要写内存，又需要写磁盘，而写磁盘的耗时相比写内存来说，肯定要慢得多，这势必会影响到 Redis 的性能。

这时我们需要分析写磁盘的细节问题，具体如下：

优化方案也很简单，Redis 写内存由主线程来做，写内存完成后就给客户端返回结果，然后 Redis 用另一个线程去写磁盘，这样就可以避免主线程写磁盘对性能的影响，也就是 Redis AOF 方案

除此之外，还可以用"数据快照"来实现，也就是 Redis RDB 方案：

- 如果业务对于数据丢失不敏感，选择 RDB；

- 如果业务对于数据完整性要求比较高，选择 AOF；

- 如果即保证数据完整性，还能让持久化文件体积更小、恢复更快 -- 混合持久化。当 AOF 在做 rewrite 时，Redis 先以 RDB 格式在 AOF 中写入一个数据快照，再把在这期间产生的每一个写命令，追加到 AOF 文件中

因为 AOF 体积进一步压缩，你在使用 AOF 恢复数据时，这个恢复时间就会更短了 ！

# 3 主从复制：多副本

一个实例宕机，只能用恢复数据来解决，那我们部署多个 Redis 实例，然后让这些实例数据保持实时同步，这样当一个实例宕机时，我们在剩下的实例中选择一个继续提供服务就好。

采用多副本的方案，它的优势是：
- 缩短不可用的时间：master 发生宕机，我们可以手动把 slave 提升为 master 继续提供服务
- 提升读性能：让 slave 分担一部分读请求，提升应用的整体性能

主从复制的问题在于，当 master 宕机时，我们需要手动把 slave 提升为 master，这个过程也需要花费时间 -- 这就引出了哨兵模式，实现故障自动切换。

# 4 哨兵模式：故障自动切换

- 哨兵每隔一段时间，询问 master 是否正常
- master 正常回复，表示状态正常，回复超时表示异常
- 哨兵发现异常，发起主从切换

这里有个问题，如果 master 状态正常，哨兵在询问 master 时网络发生了问题，哨兵可能会误判。

解决方案是部署多个哨兵，分布在不同机器上，一起监测 master 状态。

- 多个哨兵每间隔一段时间，询问 master 是否正常
- master 正常回复，表示状态正常，回复超时表示异常
- 一旦有一个哨兵判定 master 异常（不管是不是网络问题），就询问其它哨兵，如果多个哨兵（设置一个阈值）都认为 master 异常看，这才判定 master 确实发生了故障
- 多个哨兵经过协商后，判定 master 故障，则发起主从切换

# 5 分片集群

随着业务体量的爆发性增长，分片集群的解决方案顺势而生，假设一个实例扛不住写压力，可以部署多个实例，然后把这些实例按照一定的规则组织起来，把它们当作一个整体，对外提供服务：

# 5.1 客户端分配方案架构如下：

缺点是客户端需要维护这个路由规则，也就是说，你需要把路由规则写进你的业务代码中。

# 5.2 中间代理层 proxy

更进一步的优化方式是在客户端和服务端之间加一个中间代理层 proxy：

随着官方退出的 Redis Cluster 方案逐渐成熟，采用度越来越高：

无需部署哨兵集群，集群内 Redis 节点通过 Gossip 协议互相探测健康状态，在故障时发起自动切换

为了降低老业务的客户端升级成本，业界开始自研针对 proxy 的方案，架构如下：

这样，客户端无需做任何变更，只需把连接地址切到 proxy 上即可，由 proxy 负责转发数据，以及应对后面集群增删节点带来的路由变更。

至此，业界主流的 Redis 分片架构已经成型，当你使用分片集群后，对于未来更大的流量压力，也都可以从容应对了！


# 6 总结

数据怕丢失 -> 持久化（RDB/AOF）

恢复时间久 -> 主从副本（副本随时可切）

故障手动切换慢 -> 哨兵集群（自动切换）

读存在压力 -> 扩容副本（读写分离）

写存在压力/容量瓶颈 -> 分片集群

分片集群社区方案 -> Twemproxy、Codis（Redis 节点之间无通信，需要部署哨兵，可横向扩容）

分片集群官方方案 -> Redis Cluster （Redis 节点之间 Gossip 协议，无需部署哨兵，可横向扩容）

业务侧升级困难 -> Proxy + Redis Cluster（不侵入业务侧）

至此，我们的 Redis 集群才得以长期稳定、高性能的为我们的业务提供服务。

参考：

https://mp.weixin.qq.com/s/5BwWCekb_wIu6LrCdmoGCQ
